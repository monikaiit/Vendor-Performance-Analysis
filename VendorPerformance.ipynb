{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b5cc1cb-ef72-4cfb-9339-36b60768c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Ensure logs directory exists\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"logs/ingestion_db.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    filemode=\"a\"\n",
    ")\n",
    "\n",
    "engine = create_engine(\"sqlite:///inventory.db\")\n",
    "\n",
    "def ingest_db(df, table_name, engine):\n",
    "    df.to_sql(table_name, con=engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "def load_raw_data():\n",
    "    \"\"\"Load CSV files from data/ directory into SQLite database.\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    for file in os.listdir(\"data\"):\n",
    "        if file.lower().endswith(\".csv\"):\n",
    "            try:\n",
    "                df = pd.read_csv(os.path.join(\"data\", file))\n",
    "                logging.info(f\"Ingesting {file} into database\")\n",
    "                ingest_db(df, file[:-4], engine)\n",
    "            except Exception as e:\n",
    "                logging.exception(f\"Error ingesting {file}\")\n",
    "\n",
    "    end = time.time()\n",
    "    total_time = (end - start) / 60\n",
    "\n",
    "    logging.info(\"Ingestion complete\")\n",
    "    logging.info(f\"Total time taken: {total_time:.2f} minutes\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_raw_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e481b46b-5fce-4d9a-b6bf-082e193432f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<FileHandler /Users/vishnushakya/Desktop/academic/7thSem/VAR/Project/logs/get_vendor_summary.log (NOTSET)>]\n",
      "[<FileHandler /Users/vishnushakya/Desktop/academic/7thSem/VAR/Project/logs/get_vendor_summary.log (NOTSET)>]\n",
      "[<FileHandler /Users/vishnushakya/Desktop/academic/7thSem/VAR/Project/logs/get_vendor_summary.log (NOTSET)>]\n",
      "[<FileHandler /Users/vishnushakya/Desktop/academic/7thSem/VAR/Project/logs/get_vendor_summary.log (NOTSET)>]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from ingestion_db import ingest_db\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Logging Configuration\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"logs/get_vendor_summary.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    filemode=\"a\",\n",
    "    force=True\n",
    ")\n",
    "\n",
    "logging.info(\"Logging initialized successfully\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Create Vendor Summary\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def create_vendor_summary(conn):\n",
    "    \"\"\"\n",
    "    This function merges multiple tables to generate a vendor-level\n",
    "    sales and purchase summary.\n",
    "    \"\"\"\n",
    "    logging.info(\"Running vendor summary SQL query\")\n",
    "\n",
    "    vendor_sales_summary = pd.read_sql_query(\"\"\"\n",
    "    WITH FreightSummary AS (\n",
    "        SELECT\n",
    "            VendorNumber,\n",
    "            SUM(Freight) AS FreightCost\n",
    "        FROM vendor_invoice\n",
    "        GROUP BY VendorNumber\n",
    "    ),\n",
    "\n",
    "    PurchaseSummary AS (\n",
    "        SELECT\n",
    "            p.VendorNumber,\n",
    "            p.VendorName,\n",
    "            p.Brand,\n",
    "            p.Description,\n",
    "            p.PurchasePrice,\n",
    "            pp.Price AS ActualPrice,\n",
    "            pp.Volume,\n",
    "            SUM(p.Quantity) AS TotalPurchaseQuantity,\n",
    "            SUM(p.Dollars) AS TotalPurchaseDollars\n",
    "        FROM purchases p\n",
    "        JOIN purchase_prices pp\n",
    "            ON p.Brand = pp.Brand\n",
    "        WHERE p.PurchasePrice > 0\n",
    "        GROUP BY\n",
    "            p.VendorNumber,\n",
    "            p.VendorName,\n",
    "            p.Brand,\n",
    "            p.Description,\n",
    "            p.PurchasePrice,\n",
    "            pp.Price,\n",
    "            pp.Volume\n",
    "    ),\n",
    "\n",
    "    SalesSummary AS (\n",
    "        SELECT\n",
    "            VendorNo,\n",
    "            Brand,\n",
    "            SUM(SalesQuantity) AS TotalSalesQuantity,\n",
    "            SUM(SalesDollars) AS TotalSalesDollars,\n",
    "            SUM(SalesDollars) / NULLIF(SUM(SalesQuantity), 0) AS AvgSalesPrice,\n",
    "            SUM(ExciseTax) AS TotalExciseTax\n",
    "        FROM sales\n",
    "        GROUP BY VendorNo, Brand\n",
    "    )\n",
    "\n",
    "    SELECT\n",
    "        ps.VendorNumber,\n",
    "        ps.VendorName,\n",
    "        ps.Brand,\n",
    "        ps.Description,\n",
    "        ps.PurchasePrice,\n",
    "        ps.ActualPrice,\n",
    "        ps.Volume,\n",
    "        ps.TotalPurchaseQuantity,\n",
    "        ps.TotalPurchaseDollars,\n",
    "\n",
    "        ss.TotalSalesQuantity,\n",
    "        ss.TotalSalesDollars,\n",
    "        ss.AvgSalesPrice,\n",
    "        ss.TotalExciseTax,\n",
    "\n",
    "        fs.FreightCost\n",
    "\n",
    "    FROM PurchaseSummary ps\n",
    "\n",
    "    LEFT JOIN SalesSummary ss\n",
    "        ON ps.VendorNumber = ss.VendorNo\n",
    "       AND ps.Brand = ss.Brand\n",
    "\n",
    "    LEFT JOIN FreightSummary fs\n",
    "        ON ps.VendorNumber = fs.VendorNumber\n",
    "\n",
    "    ORDER BY ps.TotalPurchaseDollars DESC;\n",
    "    \"\"\", conn)\n",
    "\n",
    "    logging.info(\"Vendor summary query executed successfully\")\n",
    "    logging.info(\"\\n%s\", vendor_sales_summary.head().to_string())\n",
    "\n",
    "    return vendor_sales_summary\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Data Cleaning & Feature Engineering\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Cleans the vendor summary data and creates additional analytical columns.\n",
    "    \"\"\"\n",
    "    logging.info(\"Cleaning vendor summary data\")\n",
    "\n",
    "    # Fill missing values\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    # Trim string columns\n",
    "    df[\"VendorName\"] = df[\"VendorName\"].str.strip()\n",
    "    df[\"Description\"] = df[\"Description\"].str.strip()\n",
    "\n",
    "    # Derived metrics\n",
    "    df[\"GrossProfit\"] = df[\"TotalSalesDollars\"] - df[\"TotalPurchaseDollars\"]\n",
    "\n",
    "    df[\"ProfitMargin\"] = (\n",
    "        df[\"GrossProfit\"] /\n",
    "        df[\"TotalSalesDollars\"].replace(0, pd.NA)\n",
    "    ) * 100\n",
    "\n",
    "    df[\"StockTurnover\"] = (\n",
    "        df[\"TotalSalesQuantity\"] /\n",
    "        df[\"TotalPurchaseQuantity\"].replace(0, pd.NA)\n",
    "    )\n",
    "\n",
    "    df[\"SalesToPurchaseRatio\"] = (\n",
    "        df[\"TotalSalesDollars\"] /\n",
    "        df[\"TotalPurchaseDollars\"].replace(0, pd.NA)\n",
    "    )\n",
    "\n",
    "    print(logging.getLogger().handlers)\n",
    "    logging.info(\"Data cleaning completed\")\n",
    "    logging.info(\"\\n%s\", df.head().to_string())\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Main Execution\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        logging.info(\"Starting vendor summary pipeline\")\n",
    "        print(logging.getLogger().handlers)\n",
    "\n",
    "\n",
    "        # Database connection\n",
    "        conn = sqlite3.connect(\"inventory.db\")\n",
    "\n",
    "        # Create summary\n",
    "        summary_df = create_vendor_summary(conn)\n",
    "\n",
    "        # Clean data\n",
    "        clean_df = clean_data(summary_df)\n",
    "\n",
    "        # Ingest data\n",
    "        print(logging.getLogger().handlers)\n",
    "\n",
    "        logging.info(\"Ingesting data into vendor_sales_summary table\")\n",
    "        ingest_db(clean_df, \"vendor_sales_summary\", conn)\n",
    "\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        print(logging.getLogger().handlers)\n",
    "        logging.info(\"Pipeline completed successfully in %.2f seconds\", elapsed)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.exception(\"Pipeline failed due to an error\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21473878-b8fe-4920-920d-29239c97a8f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "Cannot operate on a closed database.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mselect * from vendor_sales_summary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/sql.py:467\u001b[0m, in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m    464\u001b[0m     dtype_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/sql.py:2264\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   2254\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2255\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2262\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2263\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m-> 2264\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2265\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   2267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/sql.py:2198\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery must be a string unless using sqlalchemy.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2197\u001b[0m args \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [params]\n\u001b[0;32m-> 2198\u001b[0m cur \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[1;32m   2199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2200\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[0;31mProgrammingError\u001b[0m: Cannot operate on a closed database."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5194ad1d-d59e-4938-8221-98c05df0fd8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
